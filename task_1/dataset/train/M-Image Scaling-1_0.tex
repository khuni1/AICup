%Input
Let $x$ be the original input image, and $y$ be the true label associated with it. The goal is to create an adversarial example $x^*$ that misleads the model while being similar to the original image $x$.

%Output
The output of the image scaling adversarial attack is an adversarial example $x^*$ generated by applying scaling transformations to the original image $x$.

%Formula
The image scaling adversarial attack can be expressed mathematically as:
$x^* = \text{Scale}(x, s) + \delta$

- $\text{Scale}(x, s)$ denotes the scaling operation applied to the image $x$ with a scaling factor $s$,
- $\delta$ represents the perturbation added to the scaled image to achieve the desired adversarial effect.

The objective can be framed as:
$\min_{\delta} \; \|x^* - x\|_p \quad \text{subject to} \quad f_\theta(x^*) \neq y$

where:
- $\|\cdot\|_p$ is the norm measuring the distance between the original and perturbed images,
- $f_\theta(x^*)$ is the model's output for the adversarial example.

%Explanation
In image scaling adversarial attacks is a  transformation-based adversarial attack , the adversary manipulates the size and dimensions of the input image to create an adversarial example. By scaling the image, the attack alters the spatial features that the model relies on for classification. The perturbation $\delta$ is then added to ensure that the model's output is different from the true label $y$. This method exploits the sensitivity of models to changes in image dimensions, allowing for the generation of adversarial examples that can evade detection while remaining visually similar to the original input.
