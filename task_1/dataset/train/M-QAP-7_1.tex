%Input
Let $x$ be the original input image, and $y$ be the true label associated with it. The goal is to create an adversarial example $x^*$ that misleads the model while incorporating the effects of quantization.

%Output
The output of the Discretized Quantization Attack is a perturbed image $x^*$ generated by applying quantization to the original input $x$ and a small perturbation $\delta$. The attack exploits the differences between continuous and discrete domains, aiming to bypass defenses that rely on discretization.

%Formula
$x^* = \text{Quantize}(x + \delta)$

where:
- $\delta$ is the perturbation added to the input $x$,
- $\text{Quantize}(\cdot)$ is a function that discretizes the values of the perturbed input to fit the required input space (e.g., mapping pixel values to integers).

%Explanation
In Discretized Quantization Attacks, the focus is on creating adversarial examples while taking into account the effects of quantization. When applying this attack, we first generate a small perturbation $\delta$ that modifies the original image $x$. The perturbation is then applied and discretized using the quantization function to produce the final adversarial example $x^*$. The goal is to ensure that $x^*$ misclassifies while remaining visually similar to $x$. This variant Quantized Adversarial Perturbation (QAP) Attack differs from the main perturbation core by incorporating the effects of quantization, which can make the attack more effective in bypassing defenses that rely on discretization.