%Input
The classifier network is denoted as $f$, which takes an input and provides a classification. The input point/image is represented by $x \in \mathbb{R}^d$. The image size is denoted by $w$, and $c$ represents the number of color channels in the image. The $\ell_p$-radius for perturbation is given by $\epsilon$. The true label of the input image is $y \in \{1, \ldots, K\}$. The number of iterations is $N$. The perturbed image that minimizes the classifier loss is $\hat{x} \in \mathbb{R}^d$. The loss function of the classifier for input $x$ and label $y$ is denoted by $L(f(x), y)$. The side length of the square to modify at iteration $i$ is $h(i)$. The perturbation added to the image is represented by $\delta$. The sampling distribution for perturbation $\delta$ is $P(\epsilon, h(i), w, c, x, \hat{x})$. The projection function that ensures the perturbed image remains within the $\ell_p$-radius and the valid pixel range is denoted by $\text{Project}(\cdot)$.

%Output
Approximate minimizer $\hat{x} \in \mathbb{R}^d$ of the problem stated.

%Formula
\subsection*{SimBA Algorithm}

1. Initialize the perturbation $\delta \leftarrow 0$.

2. Set the initial probability for the true label:
\[
p \leftarrow p_h(y | \mathbf{x})
\]

3. While the current predicted label $y$ is the most probable label, i.e., $p_y = \max_{y'} p_{y'}$:
\[
\text{Pick a random query vector } q \in Q
\]

4. For each $\alpha \in \{\epsilon, -\epsilon\}$ (explore both positive and negative perturbations):
\[
p' \leftarrow p_h(y | \mathbf{x} + \delta + \alpha q)
\]

5. If the new probability for the correct label decreases:
\[
\text{if } p'_y < p_y:
\]
    - Update the perturbation:
    \[
    \delta \leftarrow \delta + \alpha q
    \]
    - Update the probability:
    \[
    p \leftarrow p'
    \]
    - Break the loop as an improvement is found.

6. Repeat the process until the current label is no longer the most probable label.

\subsection*{Return}
The final perturbation is:
\[
\delta
\]


%Explanation
Square-based Perturbation Attack initialize $\hat{x}$ to the input image $x$. Set the initial loss $l^*$ to the classifier loss for the original image and label $L(f(x), y)$. Set the iteration counter $i$ to 1.

Continue iterating while $i < N$ and $\hat{x}$ is not adversarial. At each iteration, determine the side length $h(i)$ of the square to be modified according to some schedule. Sample a perturbation $\delta$ from the distribution $P(\epsilon, h(i), w, c, x, \hat{x})$. Project the perturbed image $\hat{x} + \delta$ onto the feasible set $\{z \in \mathbb{R}^d : \|z - x\|_p \leq \epsilon\} \cap [0, 1]^d$ to ensure that the perturbed image remains within the $\ell_p$-radius and the valid pixel range. Compute the loss $l_{\text{new}}$ for the new perturbed image $\hat{x}_{\text{new}}$. If the new loss $l_{\text{new}}$ is less than the current best loss $l^*$, update $\hat{x}$ to $\hat{x}_{\text{new}}$ and $l^*$ to $l_{\text{new}}$. Increment the iteration counter $i$ by 1.
Return the final perturbed image $\hat{x}$ as the result of the attack.
