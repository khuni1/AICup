%Input
$D = \{(\mathbf{x}_i, y_i)\}_{i=1}^n$: Original training dataset.
$f(\mathbf{w}; \mathbf{x})$: SVM model with parameter $\mathbf{w}$.
$\mathcal{L}(f, \mathbf{w}; D)$: SVM loss function (e.g., hinge loss).
$\epsilon$: Poisoning budget (fraction of data that can be poisoned).
$\eta$: Step size for optimization.
$T$: Maximum number of iterations.


%Output 
Poisoned dataset $D_{\text{adv}} = \{(\mathbf{x}_i', y_i)\}_{i=1}^n$ such that:
\[
\mathbf{w}_{\text{adv}} = \arg \min_{\mathbf{w}} \mathcal{L}(f, \mathbf{w}; D_{\text{adv}})
\quad \text{induces misclassification or performance degradation.}
\]

%Formula 
1. Initialization:
   \[
   D_{\text{adv}}^{(0)} = D.
   \]

2. Compute Gradient of Loss w.r.t Poisoned Inputs:
   \[
   \nabla_{\mathbf{x}_i'} \mathcal{L}(f, \mathbf{w}; D_{\text{adv}}) = \frac{\partial \mathcal{L}}{\partial \mathbf{w}} \cdot \frac{\partial \mathbf{w}}{\partial \mathbf{x}_i'}.
   \]

3. Update Poisoned Inputs:
   \[
   \mathbf{x}_i'^{(t+1)} = \mathbf{x}_i'^{(t)} - \eta \nabla_{\mathbf{x}_i'} \mathcal{L}(f, \mathbf{w}; D_{\text{adv}}).
   \]

4. Projection (if necessary):
   \[
   \mathbf{x}_i'^{(t+1)} = \text{Proj}_{\|\mathbf{x}_i' - \mathbf{x}_i\| \leq \epsilon} (\mathbf{x}_i'^{(t+1)}).
   \]

5. Iterative Optimization:
   - Repeat steps 2â€“4 for $T$ iterations or until convergence.

$\delta^{(0)} = 0$
for n = 1 to N:
$\delta^{(n)} = \text{Clip}_{\mathcal{X}} (\delta^{(n-1)} + \alpha \cdot \text{sign} (\nabla_\delta L(f_\theta(x + \delta^{(n-1)}), y)))$


%Explanation
The Density-Aware Poisoning Attack (DPA-SVM) variant is called PA-Density Based Perturbation. It introduces a density-based perturbation strategy inspired by the original method. The main difference between this variant and the original PA-Gradient Based Optimization is that instead of using gradient-based optimization, this variant uses density-based optimization to adjust the training points. This approach can lead to more stealthy and targeted attacks, as it allows for more nuanced manipulation of the data distribution.

In this variant, the poisoned dataset $D_{\text{adv}}$ is generated by iteratively updating the training points using a density-based optimization scheme. The updates are bounded by $\epsilon$, ensuring that the perturbations remain within a feasible region and are not easily detected. The final output is the poisoned dataset $D_{\text{adv}}$, which leads the SVM model to make incorrect predictions or fail to generalize on the test set.

This variant introduces a density-based perturbation strategy, allowing for more nuanced manipulation of the data distribution. It maintains the core principle of the original attack while improving its stealth and targeting capabilities.