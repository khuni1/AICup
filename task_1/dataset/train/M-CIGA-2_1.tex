%Input
Let \( x \) be the original input data point, but with a constraint on the magnitude of the perturbation \(\epsilon\) such that only small perturbations are allowed. The IGA generates adversarial examples through iterative updates based on the gradient of the loss function.

%Output
The output of the Modified IGA is a modified input \( x^* \) that aims to mislead the model into making an incorrect prediction, with a limited maximum perturbation magnitude.

%Formula
1. Initialize the input, true label, and number of iterations \( N \):
   $
   (x, y, N).
   $
2. For \( n = 1 \text{ to } N \):
   - Compute the gradient of the loss function:
   $
   g_n = \nabla_x J(f_{\theta}(x), y).
   $
   - Update the input using the gradient:
   $
   x = x + \min(\epsilon, \alpha) \cdot \text{sign}(g_n),
   $
   where \( \epsilon \) is the perturbation magnitude and \( \alpha \) is a new hyperparameter that controls the maximum allowed perturbation.
3. The final modified input is:
   $
   x^* = x.
   $
4. The goal is to ensure that:
   $
   f_{\theta}(x^*) \neq y.
   $

%Explanation
The ModifiedConstrained Iterative Gradient Attack (CIGA) introduces a new hyperparameter \( \alpha \) that controls the maximum allowed perturbation magnitude, limiting the size of the adversarial example generated by the attack. This modification aims to improve the stealthiness of the attack, making it more difficult for models to detect as an adversarial example. The use of the min function ensures that only small perturbations are applied, reducing the risk of over-perturbing and making the attack more targeted and effective.