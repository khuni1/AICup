%Input
The input includes the perturbation $p$, the input $x$, the target label $t$, the context $l$, and the attack function $A$. The expectation $\mathbb{E}_{x \sim X, t \sim T, l \sim L}$ averages over all possible inputs $x$ from the input space $X$, target labels $t$ from the target label space $T$, and contexts $l$ from the context space $L$.

%Output
The output includes the optimal perturbation $p_b$.

%Formula
$p_b = \text{arg max}_p \mathbb{E}_{x \sim X, t \sim T, l \sim L} [\log \text{Pr}(y_b | A(p, x, l, t))]$

%Explanation
Adversarial Patch represents an optimization problem where $p_b$ is the optimal perturbation $p$ that maximizes the log-probability of the target label $y_b$ given the input $x$, the target label $t$, and the context $l$, under the action of the attack function $A$. The expectation $\mathbb{E}_{x \sim X, t \sim T, l \sim L}$ denotes averaging over all possible inputs $x$ from the input space $X$, target labels $t$ from the target label space $T$, and contexts $l$ from the context space $L$.
