%Input
Let $\mathcal{D}$ be the dataset, $x$ be the original input, and $C_t$ be the target cluster identified using S-GAN clustering. Define $\epsilon$ as the perturbation bound, $\text{minPts}$ as the minimum points for cluster formation, and $\delta$ as the adversarial perturbation. The adversarial example $\tilde{x}$ is generated by optimizing $\delta$ such that the perturbed sample remains close to $C_t$ while misleading the model.


%Output
The output of the S-GAN based adversarial attack is a perturbed data point $\tilde{x}$ that is crafted to mislead the model while remaining close to the original input.


%Formula
1. Apply the S-GAN clustering algorithm on the dataset $\mathcal{D}$ to identify clusters:
   $
   \text{Clusters} = \text{S-GAN}(\mathcal{D}, \epsilon, \text{minPts}),
   $
   where $ \epsilon $ is the radius for neighborhood consideration and $ \text{minPts} $ is the minimum number of points to form a dense region.
2. Select a target cluster $ C_t $ containing points similar to the original input $ x $.
3. Compute the perturbation $ \delta $ as follows:
   $
   \delta = \text{argmin}_{\delta'} \| x + \delta' - C_t \|^2 \text{ subject to } \|\delta'\| \leq \epsilon.
   $
4. Generate the adversarial example:
   $
   \tilde{x} = x + \delta.
   $

%Explanation
S-GAN Clustered Adversarial Attack uses the S-GAN clustering algorithm to identify clusters of data points similar to the original input. By selecting a target cluster and minimizing the distance between the original input and the points in that cluster, the attack crafts a perturbation $ \delta $ that, when added to the original input $ x $, results in a new input $ \tilde{x} $ designed to mislead the model. This method leverages the structure of the dataset to create adversarial examples that are effective while remaining within a specified perturbation limit.

The S-GAN variant differs from the main DBSCAN method by incorporating a Generative Adversarial Network (GAN) to improve cluster identification and perturbation generation. By using a GAN, the attack can better capture complex patterns in the dataset, leading to more effective adversarial examples.