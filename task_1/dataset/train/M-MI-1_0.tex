%Input
The input includes the adversarial example $x^*$, the original input $x$, the loss function $J$, the perturbation constraint $\epsilon$, the step size $\alpha$, and the norm $p$.

%Output
The output is the adversarial example $x^*$ that maximizes the loss function subject to the perturbation constraints.

%Formula
$\text{arg max} \quad J(x^*, y), \quad \text{s.t.} \quad \| kx^* - x \|_\infty \leq \epsilon$

%Explanation
Momentum Iterative-Momentum Gradient Method where, Objective Function:
$J(x^*, y)$
This term represents the objective of the optimization problem, which is to maximize the loss function $J(x^*, y)$ with respect to the adversarial example $x^*$. It measures the degree of misclassification or adversarial effect.

Constraint:
$\| kx^* - x \|_\infty \leq \epsilon$
 This constraint limits the perturbation $x^* - x$ applied to the input $x$ such that its maximum absolute value, measured by the $\ell_\infty$-norm, does not exceed $\epsilon$. This constraint controls the magnitude of the perturbation to ensure it remains within a specified bound.

$x^*_0 = x, \quad x^*_{t+1} = x^*_t + \alpha \cdot \text{sign} \left( \nabla_x J(x^*_t, y) \right)$

Initialization:
$x^*_0 = x$
This equation initializes the adversarial example $x^*_0$ with the original input
