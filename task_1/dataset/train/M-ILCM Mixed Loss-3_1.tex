%Input
Let \( X \) be the original input, \( y_{\text{LL}} \) be the target label, and \( f(\cdot) \) and \( g(\cdot) \) be two models used for loss computation. The attack iteratively perturbs the input based on the gradients of mixed loss functions, controlled by a new hyperparameter \( \beta \).


%Output
The adversarial example \( X_{\text{adv}} \) generated by the ILCM-Mixed Loss Adversarial Attack, incorporating a mixture of two different loss functions weighted by \( \beta \).


%Formula
The formula for generating adversarial examples using the ILCM Mixed Loss Perturbation is given by:

\begin{align}
X_{\text{adv}}^0 &= X, \\
X_{\text{adv}}^{N+1} &= \text{Clip}_{X,\epsilon} \left( X_{\text{adv}}^N - \alpha \cdot \text{sign} \left( \nabla_X J(f(X_{\text{adv}}^N), y_{\text{LL}}) + \beta \cdot \nabla_X J(g(X_{\text{adv}}^N), y_{\text{LL}}) \right) \right)
\end{align}

where:
- $\alpha$ is the step size for each iteration.
- $\beta$ is a new hyperparameter that controls the mixing of two loss functions, $f$ and $g$, to create a more robust attack.
- $\text{Clip}_{X,\epsilon}(\cdot)$ ensures the perturbation stays within the $\epsilon$-ball around the original input $X$.

%Explanation
The ILCM Mixed Loss Adversarial Attack is derived from the M-ILCM Gradient Based Optimization method. The main difference lies in the introduction of a new hyperparameter, $\beta$, which allows for mixing two different loss functions, $f$ and $g$. This modification enables the attack to weigh the importance of each loss function during the adversarial example generation process. The result is a more robust and targeted attack that can effectively mislead models by incorporating multiple loss functions into the perturbation strategy.