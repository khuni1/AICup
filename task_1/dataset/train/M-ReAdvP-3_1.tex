%Input
Let $x$ be the original input image, and let $f_{\theta}$ be the target model. The goal is to generate an adversarial example $x^*$ by optimizing a perturbation $\delta$ that both misleads the classifier and preserves the ability to reconstruct the original image.

Given:
- $x$: Original input image.
- $y$: True label.
- $f_{\theta}$: Target model.
- $\delta$: Perturbation added to $x$.
- $\alpha$: Step size for iterative updates.
- $\tau$: Threshold for reconstruction fidelity.
- $\|\cdot\|_p$: Norm constraint for perturbation.
- $\|\cdot\|_q$: Norm constraint for reconstruction fidelity.
- $\text{Reconstruct}(\cdot)$: Reconstruction function.

The objective is to iteratively refine $\delta$ such that the perturbed input $x^* = x + \delta$ is misclassified while ensuring that the reconstruction of $x^*$ remains close to $x$ within a predefined threshold $\tau$.


%Output
The output $x^*$ generated by optimizing a perturbation that allows for effective reconstruction while evading the model's classification.

%Formula
$\delta^{(0)} = 0$
$\text{for } n = 1 \text{ to } N: \quad\n\delta^{(n)} = \text{Clip}_{\mathcal{X}} \left( \delta^{(n-1)} + \alpha \cdot \text{sign} \left( \nabla_\delta L(f_\theta(x + \delta^{(n-1)}), y) \right) \right)$

$\min_{\delta} \; \| \delta \|_p \quad \text{subject to} \quad f_\theta(x + \delta) \neq y \quad \text{and} \quad \| \text{Reconstruct}(x + \delta) - x \|_q \leq \tau$

%Explanation
The Reconstructive Adversarial Perturbation (ReAdvP) variant focuses on creating adversarial examples that can effectively deceive a model while preserving the ability to reconstruct the original image from the perturbed input. The main difference between this variant and the original ReCAdv attack lies in the optimization objective, where instead of directly optimizing for the minimum $L_2$ norm of the perturbation, this variant optimizes for the minimum $L_p$ norm while ensuring that the reconstructed image remains close to the original input within a specified threshold $\tau$. This generate more effective adversarial examples by balancing the trade-off between adversarial distortion and reconstruction fidelity.