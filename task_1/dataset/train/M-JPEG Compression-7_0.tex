%Input
Let $x$ be the original input image, $y$ be the true label associated with it, and $\epsilon$ be the maximum allowed perturbation. The goal is to create an adversarial example $x^*$ that misleads the model while leveraging the JPEG compression.

%Output
The output of the JPEG Adversarial Attack is an adversarial example $x^*$ that is generated by applying perturbations to the original image $x$ and then encoding it using JPEG compression.

%Formula
The JPEG Adversarial Attack can be expressed as:
$x^* = \text{JPEG}(x + \delta)$
where:
- $\delta$ is the perturbation added to the input image $x$,
- $\text{JPEG}(\cdot)$ represents the JPEG encoding process.

The objective can be formulated as:
$\min_{\delta} \; \|x^* - x\|_p \quad \text{subject to} \quad f_\theta(x^*) \neq y$
where:
- $f_\theta(x^*)$ is the model's output for the adversarial example.

%Explanation
The JPEG Adversarial Attack exploits the fact that many images undergo JPEG compression during storage and transmission. By adding a carefully crafted perturbation $\delta$ to the original image $x$, the adversary can create a perturbed image that, when compressed using JPEG, results in an adversarial example $x^*$. The JPEG encoding process introduces quantization errors that can obscure the perturbation, making it less detectable to defenses. This attack effectively leverages the vulnerabilities in image processing pipelines, generating adversarial examples that maintain a high level of visual fidelity while causing misclassification by the model.
